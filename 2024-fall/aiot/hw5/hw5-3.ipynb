{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5-3: CIFAR image classification using VGG16 or VGG19 with pretrained weights (implemented in tf.keras or PyTorch Lightning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The code in this notebook was generated using [GitHub Copilot](https://github.com/features/copilot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "\n",
    "Generate a PyTorch Lightning script for CIFAR-10 classification using:\n",
    "\n",
    "- Model: Pre-trained VGG16 from ImageNet. Replace the final layer to classify 10 CIFAR-10 classes.\n",
    "- Loss: Cross-entropy.\n",
    "- Metrics: Track training, validation, and test accuracy using torchmetrics.\n",
    "- Optimizer: AdamW with CosineAnnealingLR scheduler.\n",
    "- Data: CIFAR-10 with pre-trained model transforms.\n",
    "- Logger: TensorBoardLogger.\n",
    "- Callbacks: LearningRateMonitor, TQDMProgressBar.\n",
    "- Training: Train for 10 epochs, batch size 128, learning rate 1e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-12-17 04:06:13.068298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-17 04:06:13.078160: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-17 04:06:13.081077: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-17 04:06:13.088538: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-17 04:06:13.847527: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | VGG                | 134 M  | train\n",
      "1 | train_acc | MulticlassAccuracy | 0      | train\n",
      "2 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "134 M     Trainable params\n",
      "0         Non-trainable params\n",
      "134 M     Total params\n",
      "537.206   Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g113056077/.pyenv/versions/aiot-hw5/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g113056077/.pyenv/versions/aiot-hw5/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: |          | 0/? [00:00<?, ?it/s]\n",
      "Epoch 0: 100%|██████████| 352/352 [03:56<00:00,  1.49it/s, v_num=0, val_loss=0.330, val_acc=0.888, train_loss=0.485, train_acc=0.832]\n",
      "Epoch 1: 100%|██████████| 352/352 [03:58<00:00,  1.47it/s, v_num=0, val_loss=0.274, val_acc=0.908, train_loss=0.201, train_acc=0.931]\n",
      "Epoch 2: 100%|██████████| 352/352 [03:59<00:00,  1.47it/s, v_num=0, val_loss=0.259, val_acc=0.922, train_loss=0.0973, train_acc=0.967]\n",
      "Epoch 3: 100%|██████████| 352/352 [03:58<00:00,  1.47it/s, v_num=0, val_loss=0.269, val_acc=0.926, train_loss=0.0522, train_acc=0.981]\n",
      "Epoch 4: 100%|██████████| 352/352 [03:58<00:00,  1.47it/s, v_num=0, val_loss=0.313, val_acc=0.929, train_loss=0.0269, train_acc=0.991]\n",
      "Epoch 5: 100%|██████████| 352/352 [03:58<00:00,  1.47it/s, v_num=0, val_loss=0.323, val_acc=0.932, train_loss=0.0116, train_acc=0.996]\n",
      "Epoch 6: 100%|██████████| 352/352 [03:58<00:00,  1.47it/s, v_num=0, val_loss=0.328, val_acc=0.933, train_loss=0.00371, train_acc=0.999]\n",
      "Epoch 7: 100%|██████████| 352/352 [03:58<00:00,  1.47it/s, v_num=0, val_loss=0.363, val_acc=0.934, train_loss=0.00143, train_acc=1.000]\n",
      "Epoch 8: 100%|██████████| 352/352 [03:58<00:00,  1.47it/s, v_num=0, val_loss=0.347, val_acc=0.939, train_loss=0.000545, train_acc=1.000]\n",
      "Epoch 9: 100%|██████████| 352/352 [03:58<00:00,  1.47it/s, v_num=0, val_loss=0.346, val_acc=0.939, train_loss=0.000216, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/g113056077/.pyenv/versions/aiot-hw5/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 79/79 [00:17<00:00,  4.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9333000183105469     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36675041913986206    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9333000183105469    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36675041913986206   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.36675041913986206, 'test_acc': 0.9333000183105469}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, datasets, models\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, TQDMProgressBar\n",
    "import torchmetrics\n",
    "\n",
    "class VGG16Model(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Load the pre-trained VGG16 model and modify it\n",
    "        self.model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # freeze all layers\n",
    "        # for i, param in enumerate(self.model.features.parameters()):\n",
    "        #     param.requires_grad = False\n",
    "        \n",
    "        # Modify the final fully connected layer for 10 output classes (CIFAR-10)\n",
    "        self.model.classifier[6] = nn.Linear(4096, 10)\n",
    "\n",
    "        # Metrics\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.train_acc(logits.softmax(dim=-1), y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.val_acc(logits.softmax(dim=-1), y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.test_acc(logits.softmax(dim=-1), y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.trainer.max_epochs)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "# Data preparation for CIFAR-10\n",
    "def prepare_data():\n",
    "    transform = models.VGG16_Weights.IMAGENET1K_V1.transforms()\n",
    "    dataset = datasets.CIFAR10(\n",
    "        root=\"data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    cifar10_test = datasets.CIFAR10(\n",
    "        root=\"data\", train=False, download=True, transform=transform\n",
    "    )\n",
    "    cifar10_train, cifar10_val = random_split(dataset, [45000, 5000])\n",
    "    return cifar10_train, cifar10_val, cifar10_test\n",
    "\n",
    "\n",
    "cifar10_train, cifar10_val, cifar10_test = prepare_data()\n",
    "train_loader = DataLoader(cifar10_train, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(cifar10_val, batch_size=128)\n",
    "test_loader = DataLoader(cifar10_test, batch_size=128)\n",
    "\n",
    "# Logger and Callbacks\n",
    "logger = TensorBoardLogger(\n",
    "    \"logs5-3\",\n",
    "    name=\"cifar10_vgg16\",\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "progress_bar = TQDMProgressBar(leave=True)\n",
    "\n",
    "# Train the model\n",
    "model = VGG16Model(learning_rate=1e-4)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=logger,\n",
    "    callbacks=[lr_monitor, progress_bar],\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16Model(\n",
       "  (model): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (train_acc): MulticlassAccuracy()\n",
       "  (test_acc): MulticlassAccuracy()\n",
       "  (val_acc): MulticlassAccuracy()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-216f645ddc231b36\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-216f645ddc231b36\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"logs5-3\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiot-hw5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
